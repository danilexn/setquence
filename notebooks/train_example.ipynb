{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training SetQuence\n",
    "This notebook can be used as a template to train a SetQuence model in a supervised manner, for diverse goal tasks from training data consisting on sets of sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuring the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading modules (basic and SetQuence-specific)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from setquence.base import Config, Environment\n",
    "from setquence.data import get_dataset_loader\n",
    "from setquence.distributed import get_distributer\n",
    "from setquence.models import get_model\n",
    "from setquence.utils import get_optimizer, ns_to_dict\n",
    "from setquence.utils.metrics import classification_metrics\n",
    "from setquence.utils.slurm import slurm_config_to_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring the path to the json configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PATH = \"train_example_config.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the config\n",
    "The configuration files are loaded via the <code>Config</code> class, loaded from <code>setquence.base</code>. A <code>Path</code> containing a properly-formatted json file is passed as an argument. A configuration object is automatically generated, putting default values where missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "config = Config(Path(CONFIG_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the computational environment\n",
    "This parses the configuration from SLURM, if available, and builds an <code>Environment</code> object that contains settings such as available GPUs, or ranks (for distributed training)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slurm_env = slurm_config_to_dict()\n",
    "env = Environment(slurm_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuring the model and the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a model\n",
    "The function <code>get_model</code> initializes an instance of the model specified in <code>config.model.name</code>, as any architecture implemented in the current version of SetQuence. The configuration relative to the model (<code>config.model.config</code>) and the environment object must be passed during initialization. Model parameters are randomly initialized, except for the DNABERT encoder, if specified (see instructions at [configs/template_instructions.md](https://github.com/danilexn/setquence/blob/main/configs/template_instructions.md))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(config.model.name)(config=config.model.config, env=env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a distributer\n",
    "The function <code>get_distributer</code> initializes an instance of the <code>Distributer</code>, which takes care of moving data across workers, upon any of the specified distribution strategies (e.g., Distributed Data Parallel, Data Parallel). \n",
    "\n",
    "Then, the distributer is attached to the previously created model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = get_distributer(config.model.distributer)(env).init(config.model.distribution)\n",
    "model.distribute(dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configuring and loading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the training dataset\n",
    "Upon a specified <code>config.data.dataloader</code>, the data under <code>config.data.train</code> will be loaded via the function <code>get_dataset_loader</code>. The environment has to be passed during initialization. This is required by some dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = get_dataset_loader(config.data.dataloader)(config.data.train, env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring data-loading\n",
    "The previously initialized distributer contains a method <code>get_sampler</code>, which makes sure to return the best strategy for distributing the dataset across workers upon sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = dist.get_sampler(train_dataset, env, shuffle=config.data.train.shuffle)\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=config.data.train.batch_size,\n",
    "    num_workers=0,\n",
    "    sampler=train_sampler,\n",
    "    drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ... same for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = get_dataset_loader(config.data.dataloader)(config.data.test, env)\n",
    "test_sampler = dist.get_sampler(test_dataset, env)\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=config.data.test.batch_size,\n",
    "    num_workers=0,\n",
    "    sampler=test_sampler\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Initialize the optimizer and callback during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = get_optimizer(model, config.training.optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def callback_fn(model, *args, **kwargs):\n",
    "    prediction_list, label_list = model.predict(test_dataloader)\n",
    "    if env.rank == 0:\n",
    "        output = torch.tensor([], dtype=torch.float32)\n",
    "        for prediction in prediction_list:\n",
    "            output = torch.cat((output, prediction.to(\"cpu\")), dim=0)\n",
    "\n",
    "        labels = torch.tensor([], dtype=torch.float32)\n",
    "        for label in label_list:\n",
    "            labels = torch.cat((labels, label.to(\"cpu\")), dim=0)\n",
    "    else:\n",
    "        return\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred_labels = torch.argmax(output, dim=1)\n",
    "        probs = torch.nn.Softmax()(output)\n",
    "\n",
    "    test_metrics = classification_metrics(labels, pred_labels, probs)\n",
    "    print(test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    config.training.config,\n",
    "    train_dataloader=train_dataloader,\n",
    "    optimizer=optimizer,\n",
    "    callback_fn=callback_fn,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
